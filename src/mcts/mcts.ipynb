{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import copy\n",
    "from collections import Counter, defaultdict\n",
    "from Bio.PDB import PDBParser, Superimposer, PDBIO\n",
    "import string\n",
    "\n",
    "# define pdb parser and superimposer for biopython pdb\n",
    "parser = PDBParser()\n",
    "super_imposer = Superimposer()\n",
    "\n",
    "def superimpose(structureA, structureB, shared_chain_inA, shared_chain_inB, added_chain):\n",
    "    ref_atoms = []\n",
    "    alt_atoms = []\n",
    "\n",
    "    for res in structureA[0][shared_chain_inA]:\n",
    "        ref_atoms.append(res[\"CA\"])\n",
    "    for res in structureB[0][shared_chain_inB]:\n",
    "        alt_atoms.append(res[\"CA\"])\n",
    "\n",
    "    super_imposer.set_atoms(ref_atoms, alt_atoms)\n",
    "    super_imposer.apply(structureB.get_atoms())\n",
    "\n",
    "    structure_merged  = structureA.copy()\n",
    "    structure_merged[0].add(structureB[0][added_chain])\n",
    "    \n",
    "    return structure_merged\n",
    "\n",
    "\n",
    "def dist_comp(chainA, chainB):\n",
    "    contact_map = []\n",
    "    \n",
    "    for r_A in chainA:\n",
    "        dists = []\n",
    "        for r_B in chainB:\n",
    "            dists.append(r_A[\"CA\"] - r_B[\"CA\"])\n",
    "        contact_map += dists\n",
    "    return contact_map\n",
    "\n",
    "def check_overlaps(structure):\n",
    "    # check only the last chain\n",
    "    threshold = 3\n",
    "    overlap_percent_threshold = 0.1\n",
    "    close_end = None\n",
    "    \n",
    "    for chain in structure[0]:\n",
    "        last_chain_id = chain.get_id()\n",
    "\n",
    "    for chain in structure[0]:\n",
    "        if structure[0][last_chain_id].get_id() != chain.get_id():\n",
    "            dist = dist_comp(structure[0][last_chain_id], chain)\n",
    "            overlap_percent = len([i for i in dist if i<threshold])/(len(chain))\n",
    "            if overlap_percent > overlap_percent_threshold:\n",
    "                if 0.9> overlap_percent > 0.5:\n",
    "                    #print(overlap_percent)\n",
    "                    #print(f'close end: {structure[0][last_chain_id].get_id()} and {chain.get_id()}')\n",
    "                    close_end = chain.get_id()\n",
    "                return True, close_end\n",
    "    return False, close_end\n",
    "\n",
    "def count_interface(structure):\n",
    "    num_interface = 0\n",
    "    for chainA in structure[0]:\n",
    "        for chainB in structure[0]:\n",
    "            if chainA.get_id() != chainB.get_id():\n",
    "                contact_map = dist_comp(chainA, chainB)\n",
    "                if 8 > min(contact_map): # 8 is the threshold for interacting protein\n",
    "                    num_interface += 1\n",
    "    return num_interface/2\n",
    "\n",
    "def count_interface_chain(structure):\n",
    "    num_interface_lst = []\n",
    "    for chainA in structure[0]:\n",
    "        num_interface = 0\n",
    "        for chainB in structure[0]:\n",
    "            if chainA.get_id() != chainB.get_id():\n",
    "                contact_map = dist_comp(chainA, chainB)\n",
    "                if 12 > min(contact_map): # 8 is the threshold for interacting protein\n",
    "                    num_interface += 1\n",
    "        num_interface_lst.append(num_interface)\n",
    "    return num_interface_lst\n",
    "\n",
    "def re_name_chain(structure):\n",
    "    new_structure = structure.copy()\n",
    "    i = 0\n",
    "\n",
    "    for chain in new_structure[0]:\n",
    "        chain.id = string.ascii_lowercase[i]\n",
    "        i += 1\n",
    "    return new_structure\n",
    "\n",
    "def get_plddt(structure):\n",
    "    plddt = []\n",
    "    for chain in structure[0]:\n",
    "        for res in chain:\n",
    "            plddt.append(res[\"CA\"].get_bfactor())\n",
    "    return plddt\n",
    "        \n",
    "def score_complex(structure):\n",
    "    '''Score all interfaces in the current complex\n",
    "    '''\n",
    "    plddt = get_plddt(structure)\n",
    "    complex_score =  np.log10(count_interface(structure))*(sum(plddt)/len(plddt))\n",
    "    return complex_score\n",
    "\n",
    "def save_pdb(structure, outpath):\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(outpath)\n",
    "\n",
    "class MonteCarloTreeSearchNode():\n",
    "    def __init__(self, chain, edge_chain, source=None, structure=None, complex_scores=[0], parent=None, \n",
    "                parent_path=[], parent_pdb_path=[]):\n",
    "        self.chain = chain                  # chain that decided to be added in this decision\n",
    "        self.edge_chain = edge_chain        # chain that new chain \"added\" on\n",
    "        self.source = source                # where the chain comes from\n",
    "        self.structure = structure          # the structure exist as a biopython pdb class\n",
    "        self.complex_scores = complex_scores\n",
    "\n",
    "        self.parent = parent #Parent node\n",
    "        self.path = copy.deepcopy(parent_path) #All nodes up to (and including) the parent\n",
    "        self.path.append(chain)\n",
    "\n",
    "        self.pdb_path = copy.deepcopy(parent_pdb_path)\n",
    "        self.pdb_path.append(string.ascii_lowercase[len(self.path)-1])\n",
    "\n",
    "        self.children = [] #All nodes branching out from the current\n",
    "        self._number_of_visits = 0\n",
    "        if self.structure == None:\n",
    "            self._untried_edges, self._untried_edges_pdb, self._untried_sources, self._untried_edgesA = self.get_possible_edges_all()\n",
    "        else:\n",
    "            self._untried_edges, self._untried_edges_pdb, self._untried_sources, self._untried_edgesA = self.get_possible_edges()\n",
    "\n",
    "        self.early_stop = False\n",
    "        self.close_end = None\n",
    "        return\n",
    "\n",
    "    def get_possible_edges_all(self):\n",
    "        untried_edges = []\n",
    "        untried_edges_pdb = []  # for pdb chain, eg. [\"B\", \"C\"], [\"C\", \"D\"]\n",
    "        untried_sources = []\n",
    "        untried_edgesA = []     # for re named chain path, eg. [\"0\" ,\"0\"], [\"0\" ,\"1\"]\n",
    "        for j in range(len(self.path)):\n",
    "            #Get all edges to the current node\n",
    "            cedges = edges[np.argwhere(edges[:,0]==self.path[j])[:,0]]\n",
    "            cedges_pdb = edges_pdb[np.argwhere(edges[:,0]==self.path[j])[:,0]]\n",
    "            csources = sources[np.argwhere(edges[:,0]==self.path[j])[:,0]]\n",
    "            for i in range(len(cedges)):\n",
    "                untried_edges.append(cedges[i])\n",
    "                untried_edges_pdb.append(cedges_pdb[i])\n",
    "                untried_sources.append(csources[i])\n",
    "                untried_edgesA.append(self.pdb_path[j])\n",
    "\n",
    "        return untried_edges, untried_edges_pdb, untried_sources, untried_edgesA\n",
    "\n",
    "    def get_possible_edges(self):\n",
    "        untried_edges = []\n",
    "        untried_edges_pdb = []  # for pdb chain, eg. [\"B\", \"C\"], [\"C\", \"D\"]\n",
    "        untried_sources = []\n",
    "        untried_edgesA = []     # for re named chain path, eg. [\"0\" ,\"0\"], [\"0\" ,\"1\"]\n",
    "        # need to fix none type\n",
    "        interface_lst = count_interface_chain(self.structure)\n",
    "        shortlisted = []\n",
    "        for i in range(len(self.path)):\n",
    "            if interface_lst[i] <= min(interface_lst)+1:\n",
    "                shortlisted.append(self.path[i])\n",
    "\n",
    "        for j in range(len(shortlisted)):\n",
    "            #Get all edges to the current node\n",
    "            cedges = edges[np.argwhere(edges[:,0]==shortlisted[j])[:,0]]\n",
    "            cedges_pdb = edges_pdb[np.argwhere(edges[:,0]==shortlisted[j])[:,0]]\n",
    "            csources = sources[np.argwhere(edges[:,0]==shortlisted[j])[:,0]]\n",
    "            for i in range(len(cedges)):\n",
    "                untried_edges.append(cedges[i])\n",
    "                untried_edges_pdb.append(cedges_pdb[i])\n",
    "                untried_sources.append(csources[i])\n",
    "                untried_edgesA.append(self.pdb_path[j])\n",
    "\n",
    "        return untried_edges, untried_edges_pdb, untried_sources, untried_edgesA\n",
    "\n",
    "    def expand(self):\n",
    "        new_edge = self._untried_edges.pop()\n",
    "        new_edge_pdb = self._untried_edges_pdb.pop()\n",
    "        new_source = self._untried_sources.pop()\n",
    "        new_edgeA = self._untried_edgesA.pop()\n",
    "\n",
    "        chainA = new_edge_pdb[0]    # chain name in pairs pdb, e.g. B, C, D\n",
    "        chainA_renamed = new_edgeA  # renamed chain name, e.g. a, b, c, d\n",
    "        chainB = new_edge_pdb[1]    # chain name in pairs pdb, e.g. B, C, D\n",
    "\n",
    "        chainA_ind = new_edge[0]    # edge chain as individual chain name, e.g. 0, 1, 2\n",
    "        chainB_ind = new_edge[1]    # added chain as individual chain name, e.g. 0, 1, 2\n",
    "\n",
    "\n",
    "        if self.structure == None:\n",
    "            #first node\n",
    "            child_structure = parser.get_structure(\"child\", new_source)\n",
    "        elif self.structure != None:\n",
    "            source_structure = parser.get_structure(\"child\", new_source)\n",
    "            child_structure = superimpose(self.structure, source_structure, chainA_renamed, chainA, chainB)\n",
    "\n",
    "        child_structure = re_name_chain(child_structure)\n",
    "        overlap, close_end = check_overlaps(child_structure)\n",
    "\n",
    "        if not overlap:\n",
    "            complex_score = score_complex(child_structure)\n",
    "            child_node = MonteCarloTreeSearchNode(chainB_ind, chainA_ind, source=new_source, \n",
    "                                                    structure=child_structure, complex_scores=[complex_score], \n",
    "                                                    parent=self, parent_path=self.path, parent_pdb_path=self.pdb_path)\n",
    "        elif overlap:\n",
    "            if close_end != None:\n",
    "                self.close_end = f'{chainA_renamed}, {close_end}'\n",
    "                self.close_end_source = new_source\n",
    "            return self\n",
    "\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "    def rollout(self):\n",
    "            '''Simulate an assembly path until\n",
    "            1. all chains are in complex\n",
    "            2. an overlap is found\n",
    "            '''\n",
    "            overlap = False\n",
    "\n",
    "            path_node = copy.deepcopy(self)\n",
    "\n",
    "            while len(path_node.path)<26 and overlap==False:\n",
    "                if len(path_node._untried_edges)>0:\n",
    "                    edge_ind = np.random.randint(len(path_node._untried_edges))\n",
    "                else:\n",
    "                    overlap=True\n",
    "                    break\n",
    "\n",
    "                new_edge = path_node._untried_edges[edge_ind]\n",
    "                new_edge_pdb = path_node._untried_edges_pdb[edge_ind]\n",
    "                new_source = path_node._untried_sources[edge_ind]\n",
    "                new_edgeA = path_node._untried_edgesA[edge_ind]\n",
    "\n",
    "                chainA = new_edge_pdb[0]\n",
    "                chainA_renamed = new_edgeA\n",
    "                chainB = new_edge_pdb[1]\n",
    "\n",
    "                chainA_ind = new_edge[0]    # edge chain as individual chain name, e.g. 0, 1, 2\n",
    "                chainB_ind = new_edge[1]    # added chain as individual chain name, e.g. 0, 1, 2\n",
    "\n",
    "                print(f'{new_source} {chainA_renamed} {chainA} {chainB}')\n",
    "\n",
    "                if path_node.structure != None:\n",
    "                    source_structure = parser.get_structure(\"child\", new_source)\n",
    "                    child_structure = superimpose(path_node.structure, source_structure, chainA_renamed, chainA, chainB)\n",
    "                elif path_node.structure == None: #root node\n",
    "                    child_structure = parser.get_structure(\"child\", new_source)\n",
    "                    \n",
    "                child_structure = re_name_chain(child_structure)\n",
    "                \n",
    "                #Check overlaps\n",
    "                overlap, close_end = check_overlaps(child_structure)\n",
    "\n",
    "                #If no overlap - score and create a child node\n",
    "                if overlap==False:\n",
    "                    path_node = MonteCarloTreeSearchNode(chainB_ind, chainA_ind, source=new_source, structure=child_structure, \n",
    "                                                            complex_scores=[0], parent=path_node, parent_path=path_node.path, \n",
    "                                                            parent_pdb_path=path_node.pdb_path)\n",
    "                elif overlap==True:\n",
    "                    break\n",
    "            #Score rollout\n",
    "            if path_node.structure != None:\n",
    "                rollout_score = score_complex(path_node.structure)\n",
    "            elif path_node.structure == None:\n",
    "                rollout_score = 0\n",
    "            return rollout_score\n",
    "\n",
    "    def back_prop(self, rollout_score):\n",
    "        '''Update the previous nodes in the path\n",
    "        '''\n",
    "        self._number_of_visits += 1\n",
    "        self.complex_scores.append(rollout_score)\n",
    "        #This is recursive and will back_prop to all parents\n",
    "        if self.parent:\n",
    "            self.parent.back_prop(rollout_score)\n",
    "\n",
    "    def best_child(self):\n",
    "        '''Calculate the UCB\n",
    "\n",
    "        Vi is the average reward/value of all nodes beneath this node (sum of interface scores)\n",
    "        N is the number of times the parent node has been visited, and\n",
    "        ni is the number of times the child node i has been visited\n",
    "\n",
    "        The first component of the formula above corresponds to exploitation;\n",
    "        it is high for moves with high average win ratio.\n",
    "        The second component corresponds to exploration; it is high for moves with few simulations.\n",
    "        '''\n",
    "        choices_weights = [(np.average(c.complex_scores) + 2 * np.sqrt(np.log(c.parent._number_of_visits+1e-3) / (c._number_of_visits+1e-12))) for c in self.children]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def tree_policy(self):\n",
    "        current_node = self\n",
    "        fully_expanded = (len(current_node._untried_edges) == 0)\n",
    "        while len(current_node.path) < 26:\n",
    "            if fully_expanded:\n",
    "                if len(current_node.children) != 0:\n",
    "                    current_node = current_node.best_child()\n",
    "                elif len(current_node.children)==0:\n",
    "                    current_node.early_stop = True\n",
    "                return current_node\n",
    "            elif not fully_expanded:\n",
    "                return current_node.expand()\n",
    "\n",
    "    def best_action(self):\n",
    "        simulation_no = 50\n",
    "        \n",
    "        for i in range(simulation_no):\n",
    "            v = self.tree_policy()\n",
    "            if v != None: # if not None\n",
    "                reward = v.rollout()\n",
    "                v.back_prop(reward)\n",
    "                print(v.path)\n",
    "        if len(self.children) > 0:\n",
    "            return self.best_child()\n",
    "        else:\n",
    "            return self\n",
    "\n",
    "def main():\n",
    "    root = MonteCarloTreeSearchNode('0', '', source=None, structure=None, complex_scores=[0], parent=None, parent_path=[], parent_pdb_path=[])\n",
    "\n",
    "    v = root\n",
    "\n",
    "    step = 1\n",
    "    \n",
    "    if not os.path.exists(f'{output}'):\n",
    "        os.makedirs(f'{output}')\n",
    "    \n",
    "    for _ in range(30):\n",
    "        v = v.best_action()\n",
    "        save_pdb(v.structure, f'{output}{args.id}_step{str(step)}.pdb')\n",
    "        step += 1\n",
    "        if v.early_stop:\n",
    "            print(\"early stop\")\n",
    "            break\n",
    "\n",
    "    save_pdb(v.structure, f'{output}{args.id}_final.pdb')\n",
    "\n",
    "    # writing output csv\n",
    "    pairs_lst = []\n",
    "    source_lst = []\n",
    "\n",
    "    if v.close_end != None:\n",
    "        print('close end', v.close_end, v.close_end_source)\n",
    "        with open(f'{output}{args.id}_close.txt', \"w\") as text_file:\n",
    "            text_file.write(f'{v.close_end},{v.close_end_source}')\n",
    "\n",
    "    for i in range(len(v.pdb_path)-1):\n",
    "        pairs_lst.append(f'{v.pdb_path[i]},{v.pdb_path[i+1]}')\n",
    "    if v.close_end != None:\n",
    "        pairs_lst.append(v.close_end)\n",
    "        source_lst.append(v.close_end_source)\n",
    "\n",
    "    w = v\n",
    "    \n",
    "    while w.source:\n",
    "        source_lst.append(w.source)\n",
    "        w = w.parent\n",
    "    source_lst.reverse()\n",
    "\n",
    "    out_lst = []\n",
    "    out_lst.append(f'output/{args.id}/mcts/{args.id}_final.pdb')\n",
    "    out_lst.append(\" \".join(v.pdb_path))\n",
    "    out_lst.append(\" \".join(v.path))\n",
    "    out_lst = out_lst + [f'{pairs_lst[i]},{source_lst[i]}' for i in range(len(source_lst))]\n",
    "\n",
    "    with open(f'{output}{args.id}_path.txt', 'w') as f:\n",
    "        for line in out_lst:\n",
    "            f.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_dir = '../../output/1AVO/pairs/*'\n",
    "pair_paths = glob.glob(pairs_dir)\n",
    "\n",
    "edges = []\n",
    "edges_pdb = []\n",
    "sources = pair_paths\n",
    "for file_path in pair_paths:\n",
    "    name = os.path.basename(file_path)[:-4]\n",
    "    edges_lst = (name.split('_')[3]).split('-')\n",
    "    edges_pdb_lst = (name.split('_')[4]).split('-')\n",
    "    edges.append(edges_lst)\n",
    "    edges_pdb.append(edges_pdb_lst)\n",
    "    #edges.append([name[-9], name[-8]])\n",
    "    #edges_pdb.append([name[-6], name[-5]])\n",
    "\n",
    "edges = np.array(edges)\n",
    "edges_pdb = np.array(edges_pdb)\n",
    "sources = np.array(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = MonteCarloTreeSearchNode('0', '', source=None, structure=None, complex_scores=[0], parent=None, parent_path=[], parent_pdb_path=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = root.expand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v._untried_edgesA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('IMP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "351fd177af4a0d74e5700f0e3aba1cf44ab8e45f831ea7f0b02992477caefab2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
